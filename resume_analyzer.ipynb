{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\dhara\\anaconda3\\lib\\site-packages (0.11.6)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytesseract in c:\\users\\dhara\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\dhara\\anaconda3\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pdfplumber) (10.2.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (42.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "ROSAN S\n",
      "DATA ANALYST\n",
      "91+ 7708126918 / roshandharan00@gmail.com / linkedin.com/in/Rosans\n",
      "SUMMARY\n",
      "Motivated and detail-oriented Data Analyst with a strong foundation in data visualization, statistical\n",
      "analysis, and programming. Proficient in Python, Power BI, Machine learning, SQL , R program and Tableau.I am\n",
      "eager to apply my skills to real-world projects and contribute to organizational growth. My goal is to leverage\n",
      "data insights to drive strategic initiatives and deliver measurable business outcomes.\n",
      "SKILLS\n",
      "Python Excel Data cleaning & wrangling Hypothesis Testing\n",
      "Data Visualization SQL R program Data-Driven Decision Making\n",
      "Power bi Webscraping Descriptive statistics Presentation Skills\n",
      "CERTIFICATION\n",
      "MongoDB and the Document Model – MongoDB (Aug 24, 2024)\n",
      "Communication Skills – TCS iON (Sep 26, 2024)\n",
      "Association Analysis using Python – Wingspan (Jan 5, 2025)\n",
      "Data Modeling and Visualization – TCS iON (Mar 11, 2025)\n",
      "EDUCATION\n",
      "Bachelor of Computer Science with Data Analytics\n",
      "SRI RAMAKRISHANA COLLEGE OF ARTS AND SCIENCE\n",
      "08/2023 - 05/2026\n",
      "HIGHER SECONDARY\n",
      "GOVERNMENT HIGHER SECONDARY SCHOOL\n",
      "2023\n",
      "WORK EXPERIENCE FEB 2025 - MAR 2025\n",
      "Data Analyst Intern at Excelerate | GlobalShala\n",
      "Analyzed Facebook ad campaign data for the Superhero U event to identify underperforming campaigns,\n",
      "resulting in cost savings recommendations for the Finance team.\n",
      "Utilized Python and Power BI to create interactive dashboards for campaign performance analysis.\n",
      "Implemented A/B testing methodologies to determine optimal marketing strategies.PROJECTS\n",
      "03/2025\n",
      "Facebook Ad Campaign Performance Analysis\n",
      "Analyzed Facebook ad campaign data for the Superhero U event to identify underperforming campaigns,\n",
      "resulting in cost savings recommendations for the Finance team.\n",
      "Utilized Python and Power BI to create interactive dashboards for campaign performance analysis.\n",
      "Implemented A/B testing methodologies to determine optimal marketing strategies.\n",
      "07/2025- 16/2025\n",
      "Crop Recommendation System\n",
      "Developed a Machine Learning model to recommend the most suitable crops based on soil type,\n",
      "climate conditions, and historical yield data.\n",
      "Utilized Random Forest and Decision Tree algorithms for accurate predictions.\n",
      "Developed a Flask-based web application integrating the Random Forest model for real-time crop\n",
      "predictions.\n",
      "Implemented data preprocessing, model training, and API integration for seamless user interaction.\n",
      "KEY ACHIVEMENTS\n",
      "Internshala Student Partner (ISP) | Aug 2024 - Mar 2025\n",
      "Promoted Internshala’s services and opportunities on campus through social media, word-of-mouth, and\n",
      "organized events.\n",
      "Presented a paper at the International Collaborative\n",
      "Business Analytics Conference (ICBAC '24) on \"Generative Artificial Intelligence in the Analytical Era\" in\n",
      "association with Ostfalia University (Germany) & SEGi University (Malaysia).\n",
      "DECLERATION\n",
      "I hereby declare that all the information provided in this RESUME is true and correct to the best of my\n",
      "knowledge and belief. I take full responsibility for the accuracy of the details mentioned above.\n",
      "ROSAN S\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"uploaded_resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in c:\\users\\dhara\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dhara\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (2.25.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (2.170.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (2.40.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google.generativeai) (4.9.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.72.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhara\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of India?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0026347806677222254\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 10,\n",
      "        \"total_token_count\": 17\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
    "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to imorve his resume , alos suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following job description:\n",
    "        \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Evaluation: Rosan S - Data Analyst\n",
      "\n",
      "**Overall Assessment:** Rosan's resume shows promise for an entry-level Data Analyst role, particularly given his recent internship and project experience. However, it needs significant improvement in structure, quantifiable results, and showcasing a broader range of skills.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Strong foundational skills:** He possesses a solid base in Python, SQL, Power BI, and R, which are essential for data analysis.\n",
      "* **Relevant Projects:** The Facebook Ad Campaign analysis and Crop Recommendation System projects demonstrate practical application of his skills.  These are good starting points.\n",
      "* **Certifications:** While some certifications are quite recent, they show a proactive approach to learning and skill development.  They are still in progress, so that timeline is notable.\n",
      "* **Presentation Skills & Conference Presentation:** Presenting at ICBAC demonstrates communication and presentation abilities, crucial for a data analyst.\n",
      "* **Internship Experience:** The internship at Excelerate provides valuable real-world experience.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Resume Structure:** The resume is poorly structured.  Information is repetitive (the Facebook Ad project is listed twice).  A more concise and impactful structure is needed, focusing on achievements and quantifiable results.\n",
      "* **Lack of Quantifiable Results:** While he mentions cost savings, the amount is not specified. Quantifying achievements (e.g., \"reduced ad spend by 15%,\" \"improved campaign conversion rate by 10%\") significantly strengthens the resume.\n",
      "* **Limited Project Depth:** The project descriptions are superficial.  They need more detail on the challenges faced, methodologies used, and the impact of his work.\n",
      "* **Education Timeline:**  The education section shows a timeline inconsistency.  He graduated Higher Secondary in 2023 and is still pursuing his Bachelor's degree (2023-2026).  This needs clarification.\n",
      "* **Skills Section Needs Improvement:** The skills section is a simple list, lacking in context and depth.  Categorizing skills (e.g., programming languages, data visualization tools, statistical methods) would make it more readable and impactful.\n",
      "* **Overemphasis on Recent Activities:** The resume heavily emphasizes activities from 2025, leaving the impression that the candidate has limited experience before that.\n",
      "\n",
      "\n",
      "**Skills Rosan Already Has:**\n",
      "\n",
      "* Python\n",
      "* SQL\n",
      "* R\n",
      "* Power BI\n",
      "* Tableau\n",
      "* Data Cleaning & Wrangling\n",
      "* Data Visualization\n",
      "* Hypothesis Testing\n",
      "* Descriptive Statistics\n",
      "* Web Scraping\n",
      "* A/B Testing\n",
      "* Machine Learning (basic application - Random Forest, Decision Tree)\n",
      "* Flask (web framework)\n",
      "* Data Modeling (basic)\n",
      "* Presentation Skills\n",
      "* Communication Skills\n",
      "\n",
      "\n",
      "**Skills to Improve:**\n",
      "\n",
      "* **Advanced Statistical Modeling:**  Go beyond descriptive statistics; master inferential statistics, regression analysis, time series analysis, etc.\n",
      "* **Data Mining Techniques:**  Explore techniques like clustering, classification, and association rule mining more deeply.\n",
      "* **Big Data Technologies:** Gain familiarity with tools like Hadoop, Spark, or cloud-based solutions (AWS, Azure, GCP) depending on the job role's requirements.\n",
      "* **Database Management:** Enhance SQL skills to include database design and optimization.\n",
      "* **Version Control (Git):** Essential for collaborative projects.\n",
      "* **Cloud Computing:** Familiarity with cloud platforms would enhance job prospects.\n",
      "* **Data Storytelling:**  Learn to effectively communicate insights through compelling narratives and visualizations.\n",
      "\n",
      "\n",
      "**Suggested Courses:**\n",
      "\n",
      "* **Advanced Statistical Modeling:** Coursera, edX, DataCamp courses on regression analysis, time series analysis, and advanced statistical methods.\n",
      "* **Big Data Technologies:** Courses on Hadoop, Spark, or cloud platforms (AWS, Azure, GCP) from Coursera, edX, or cloud provider training programs.\n",
      "* **Data Visualization with Tableau/Power BI:** Advanced courses focusing on dashboard design and storytelling.\n",
      "* **Machine Learning Specialization:**  A specialization from Coursera, edX, or Udacity to deepen his machine learning knowledge.\n",
      "* **Git and GitHub:**  Numerous online tutorials and courses are available.\n",
      "\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. **Revise the Resume Structure:** Use a chronological or functional format with clear headings and concise descriptions.\n",
      "2. **Quantify Achievements:** Add specific numbers and metrics to highlight the impact of his work.  For example, instead of \"resulting in cost savings recommendations,\" say \"recommended changes that reduced Facebook ad spend by 15%, resulting in $X savings.\"\n",
      "3. **Elaborate on Projects:** Expand project descriptions to include challenges, solutions, and results.  Use the STAR method (Situation, Task, Action, Result) to structure descriptions.\n",
      "4. **Improve Skills Section:**  Organize skills into categories and use keywords relevant to data analyst job descriptions.\n",
      "5. **Address Education Timeline:** Clarify the apparent inconsistency in the education timeline.\n",
      "6. **Add a Portfolio:**  Create a portfolio showcasing his projects and visualizations.  This allows recruiters to assess his skills directly.\n",
      "\n",
      "\n",
      "By addressing these weaknesses and incorporating the suggestions above, Rosan can significantly improve his resume and increase his chances of securing a Data Analyst position.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
